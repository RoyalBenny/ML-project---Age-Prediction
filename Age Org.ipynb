{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('F:\\\\Installed Softwares\\\\Anaconda\\\\envs\\\\opencv-env\\\\Lib\\\\site-packages')\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\roval\\\\Downloads\\\\Age-Prediction-master'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "class Dataset(object):\n",
    "\n",
    "\n",
    "    #calling init method.\n",
    "    def __init__(self,l=[],f=[],t=os.listdir()):\n",
    "        self.l = l\n",
    "        self.f = f\n",
    "        self.t = t\n",
    "\n",
    "    #creating classmethod and defining features dataset.\n",
    "    @classmethod\n",
    "    def createdatafeatures(self):\n",
    "        \n",
    "        #provide path to your scaled dataset .\n",
    "        fd = open('C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/foo1.csv','a+')\n",
    "        \n",
    "        #creating list of images.\n",
    "        t = os.listdir()\n",
    "        \n",
    "        #looping through all the images and extracting features.\n",
    "        for k in t:\n",
    "            \n",
    "            #reading image and conversion to greay scale image.\n",
    "            img = cv2.imread(k,0)\n",
    "            \n",
    "            #image resizing\n",
    "            img = cv2.resize(img,(10,10))\n",
    "            \n",
    "            #conversion of image matrix to aimage array.\n",
    "            img = img.flatten().reshape(-1,1).transpose()\n",
    "            \n",
    "            #writing each array to a csv file.\n",
    "            for i in img[0]:\n",
    "                fd.write(str(i)+str(\",\"))\n",
    "            fd.write(\"\\n\")        \n",
    "\n",
    "        #returning and closing the file.\n",
    "        return fd.close()\n",
    "    \n",
    "    #creating classmethod and creating output dataset.\n",
    "    @classmethod\n",
    "    def createdataoutput(self):\n",
    "        \n",
    "        #providing location of output dataset csv file.\n",
    "        fe = open(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/foo.csv\",\"a+\")\n",
    "        \n",
    "        #storing the list of images in the directory.\n",
    "        t = os.listdir()\n",
    "        \n",
    "        #looping through all the mages.\n",
    "        for i in range(len(t)):\n",
    "            \n",
    "            #computing the age provided in the image name and writing n the output csv file.\n",
    "            fe.write(str(abs(int(t[i].split(\"_\")[1][:4])-int(t[i].split(\"_\")[2][:4]))))\n",
    "            fe.write(\"\\n\")\n",
    "\n",
    "        #returning and closing the file\n",
    "        return fe.close()\n",
    "\n",
    "#main method\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #displaying the doc method.\n",
    "    print(__doc__)\n",
    "    \n",
    "    #changing the directory to the grey scaled image folder.\n",
    "    os.chdir(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/sample_greyed\")\n",
    "\n",
    "    #creating object\n",
    "    obj = Dataset()\n",
    "    \n",
    "    #creating object functions.\n",
    "    obj.createdatafeatures()\n",
    "    obj.createdataoutput()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import keras.models\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "WARNING:tensorflow:From F:\\Installed Softwares\\Anaconda\\envs\\opencv-env\\Lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\roval\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From F:\\Installed Softwares\\Anaconda\\envs\\opencv-env\\Lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Installed Softwares\\Anaconda\\envs\\opencv-env\\Lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "def find_marker(image):\n",
    "\t# convert the image to grayscale, blur it, and detect edges\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\tedged = cv2.Canny(gray, 35, 125)\n",
    "\n",
    "\t# find the contours in the edged image and keep the largest one;\n",
    "\t# we'll assume that this is our piece of paper in the image\n",
    "\tcontours,hierachy=cv2.findContours(edged.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\tc = max(contours, key = cv2.contourArea)\n",
    "\n",
    "\t# compute the bounding box of the of the paper region and return it\n",
    "\treturn cv2.minAreaRect(c)\n",
    "\n",
    "def distance_to_camera(knownWidth, focalLength, perWidth):\n",
    "\t# compute and return the distance from the maker to the camera\n",
    "\treturn (knownWidth * focalLength) / perWidth\n",
    "\n",
    "# initialize the known distance from the camera to the object, which\n",
    "# in this case is 24 inches\n",
    "KNOWN_DISTANCE = 14\n",
    "\n",
    "# initialize the known object width, which in this case, the piece of\n",
    "# paper is 12 inches wide\n",
    "KNOWN_WIDTH = 5\n",
    "\n",
    "# initialize the list of images that we'll be using\n",
    "#IMAGE_PATHS = []\n",
    "\n",
    "# load the furst image that contains an object that is KNOWN TO BE 2 feet\n",
    "# from our camera, then find the paper marker in the image, and initialize\n",
    "# the focal length\n",
    "image = cv2.imread(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/training_pic/trainpic.jpg\",1)\n",
    "marker = find_marker(image)\n",
    "focalLength = (marker[1][0] * KNOWN_DISTANCE) / KNOWN_WIDTH\n",
    "\n",
    "\n",
    "#Capturing Images.\n",
    "cap=cv2.VideoCapture(0) #For Primary webcam\n",
    "\n",
    "#To use recoded vedio as a feed \n",
    "'''cap=cv2.VedioCapture('Location of the vedio')'''\n",
    "\n",
    "\n",
    "#To save each frames \n",
    "#fourcc=cv2.VedioWriter(\"Output_name.avi\",fourcc,20.0,(720,640))#(720,640)==720x640 pixel values.It depends on the Webcam quality.\n",
    "\n",
    "clf1 = keras.models.load_model(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/Model/gclf.h5py\")\n",
    "\n",
    "clf = pickle.load(open(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/Model/clf.pkl\",\"rb\"))\n",
    "\n",
    "\n",
    "#Loading the cascade classifier files\n",
    "face_cascade=cv2.CascadeClassifier('Haarcascades_Datasets/haarcascade_frontalface_default.xml')#copy the locations\n",
    "\n",
    "eye_cascade=cv2.CascadeClassifier('Haarcascades_Datasets/haarcascade_eye.xml')#copy the locations\n",
    "\n",
    "#looping through the webcam feed\n",
    "cap.open(1)\n",
    "print(cap.get(1))\n",
    "if cap.isOpened():\n",
    "\twhile 1:\n",
    "           \n",
    "        \t#reading the frame\n",
    "        \tret, img=cap.read()\n",
    "        \tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "\t\n",
    "\t\n",
    "        \tim = cv2.resize(img,(64,64))\n",
    "\t\n",
    "        \tbailey = np.expand_dims(im, axis=0)\n",
    "        \t\n",
    "        \tprediction_b = clf1.predict(bailey)\n",
    "\t\n",
    "        \tif math.floor(prediction_b) >=0.15:\n",
    "\t\n",
    "        \t        prediction_b = \"Female\"\n",
    "        \t        \n",
    "        \telse:\n",
    "        \t        prediction_b = \"Male\"\n",
    "        \t\n",
    "\t\n",
    "        \t#detection of facial coordinates\n",
    "        \tfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \t\n",
    "       \t\t#creating rectangles\n",
    "        \tfor (x,y,w,h) in faces:\n",
    "                \n",
    "                #in face\n",
    "                \tcv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                \n",
    "                #extracting the facial part\n",
    "                \troi_gray = gray[y:y+h, x:x+w]\n",
    "                \n",
    "                \troi_color = img[y:y+h, x:x+w]\n",
    "                \n",
    "                #reshaping for prediction\n",
    "                \tsimg = cv2.resize(roi_gray,(10,10))\n",
    "                \n",
    "                #flattening\n",
    "                \tsimg = simg.flatten().reshape(-1,1)\n",
    "                \n",
    "                #transpose\n",
    "                \tsimg = simg.T/10.0\n",
    "                                \n",
    "                #predicting the value\n",
    "                \tres = clf.predict(simg)\n",
    "                \n",
    "                #reduction for noise\n",
    "                \tif res:\n",
    "                        \tprint(\"Gender :{}\\tPredicted Age is :{}\".format((prediction_b),abs(res+20)//2))\n",
    "                        \n",
    "                #detection of eyes\n",
    "                \teyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "                \tmarker = find_marker(roi_color)\n",
    "                \n",
    "                \tinches = distance_to_camera(KNOWN_WIDTH, focalLength, marker[1][0])\n",
    "                \n",
    "                \tcv2.putText(img, \"%.2fft\" % (inches / 12),(x , y), cv2.FONT_HERSHEY_SIMPLEX,2.0, (0, 255, 255), 1)\n",
    "\n",
    "                \n",
    "                #looping through eye coordinates\n",
    "                \tfor (ex,ey,ew,eh) in eyes:\n",
    "                        \n",
    "                        #creating rectangles\n",
    "                        \tcv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "        #displaying the image\n",
    "        \tcv2.imshow('img',img)\n",
    "        \n",
    "        #wait key\n",
    "        \tk = cv2.waitKey(30) & 0xff\n",
    "        \tif k == 27:\n",
    "                \tbreak\n",
    "        \n",
    "#releasing the webcamfeed\n",
    "cap.release()\n",
    "\n",
    "#closing all the window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_marker(image):\n",
    "\t# convert the image to grayscale, blur it, and detect edges\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\tedged = cv2.Canny(gray, 35, 125)\n",
    "\n",
    "\t# find the contours in the edged image and keep the largest one;\n",
    "\t# we'll assume that this is our piece of paper in the image\n",
    "\tcontours,hierachy=cv2.findContours(edged.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\tc = max(contours, key = cv2.contourArea)\n",
    "\n",
    "\t# compute the bounding box of the of the paper region and return it\n",
    "\treturn cv2.minAreaRect(c)\n",
    "image = cv2.imread(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/training_pic/trainpic.jpg\")\n",
    "marker = find_marker(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_camera(knownWidth, focalLength, perWidth):\n",
    "\t# compute and return the distance from the maker to the camera\n",
    "\treturn (knownWidth * focalLength) / perWidth\n",
    "\n",
    "# initialize the known distance from the camera to the object, which\n",
    "# in this case is 24 inches\n",
    "KNOWN_DISTANCE = 14\n",
    "\n",
    "# initialize the known object width, which in this case, the piece of\n",
    "# paper is 12 inches wide\n",
    "KNOWN_WIDTH = 5\n",
    "\n",
    "# initialize the list of images that we'll be using\n",
    "#IMAGE_PATHS = []\n",
    "\n",
    "# load the furst image that contains an object that is KNOWN TO BE 2 feet\n",
    "# from our camera, then find the paper marker in the image, and initialize\n",
    "# the focal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"C://Users/roval/Documents/Age-Prediction-master/Age-Prediction-master/training_pic/trainpic.jpg\")\n",
    "marker = find_marker(image)\n",
    "focalLength = (marker[1][0] * KNOWN_DISTANCE) / KNOWN_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
